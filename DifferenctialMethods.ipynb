{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIFFERENTIAL METHODS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some useful libraries for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this notebook, we will use the CIFAR-10 dataset for testing purpose. Here is a script that loads the dataset into training set and test set. We will apply the differential methods to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 32, 32, 3)\n",
      "Training labels shape:  (50000, 1)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the raw CIFAR-10 data.\n",
    "cifar10_dir = r'C:\\Users\\alexa\\OneDrive\\Bureau\\projet clustering\\kmeans_clusters\\cluster_fold\\C1'\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', x_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.load('kmeans_cifar10.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 54,  31,  18],\n",
       "         [ 59,  34,  19],\n",
       "         [ 56,  37,  22],\n",
       "         ...,\n",
       "         [133,  92,  53],\n",
       "         [131,  89,  49],\n",
       "         [132,  94,  53]],\n",
       "\n",
       "        [[ 59,  38,  26],\n",
       "         [ 62,  39,  26],\n",
       "         [ 55,  36,  25],\n",
       "         ...,\n",
       "         [193, 135,  77],\n",
       "         [200, 144,  86],\n",
       "         [197, 142,  86]],\n",
       "\n",
       "        [[ 41,  26,  18],\n",
       "         [ 41,  25,  16],\n",
       "         [ 36,  21,  13],\n",
       "         ...,\n",
       "         [202, 144,  84],\n",
       "         [196, 141,  81],\n",
       "         [190, 136,  79]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[105, 161, 157],\n",
       "         [ 97, 163, 162],\n",
       "         [ 96, 170, 164],\n",
       "         ...,\n",
       "         [ 98, 145, 144],\n",
       "         [100, 138, 135],\n",
       "         [100, 130, 123]],\n",
       "\n",
       "        [[ 86, 149, 143],\n",
       "         [ 96, 157, 156],\n",
       "         [ 97, 164, 160],\n",
       "         ...,\n",
       "         [ 94, 127, 122],\n",
       "         [ 98, 126, 120],\n",
       "         [100, 124, 114]],\n",
       "\n",
       "        [[ 70, 136, 128],\n",
       "         [ 92, 146, 145],\n",
       "         [113, 169, 168],\n",
       "         ...,\n",
       "         [ 98, 121, 111],\n",
       "         [ 96, 117, 106],\n",
       "         [ 92, 112, 101]]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-max differential method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that the images in this set are **very similar**, we call `I_min` and `I_max` the minimum and the maximum images, respectively.\n",
    "\n",
    "**For the encoder**\n",
    "- For each channel:\n",
    "    - We start by defaul by using distance to `I_min`\n",
    "    - We continue using the distance to to `I_min` utill this distance is greater than the distance to to `I_max`, we switch !\n",
    "\n",
    "**For the decoder**\n",
    "- We just do the same things as reversed order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a naive approche, start by encoding a single channel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_encoder_note(channel, min_channel, max_channel, start_by_min = True):\n",
    "    H, W = channel.shape\n",
    "    encoded_channel = np.zeros((H,W))\n",
    "    is_min = start_by_min\n",
    "    for h in range(H):\n",
    "        for w in range(W):\n",
    "            dis_to_min = channel[h,w] - min_channel[h,w]\n",
    "            dis_to_max = max_channel[h,w] - channel[h,w]\n",
    "            if is_min == True:\n",
    "                encoded_channel[h,w] = dis_to_min\n",
    "            if is_min == False:\n",
    "                encoded_channel[h,w] = dis_to_max\n",
    "            \n",
    "            is_min = dis_to_min <= dis_to_max\n",
    "            \n",
    "    return encoded_channel\n",
    "\n",
    "def channel_decoder_note(encoded_channel, min_channel,max_channel, start_by_min = True):\n",
    "    H, W = encoded_channel.shape\n",
    "    decoded_channel = np.zeros((H,W))\n",
    "    is_min = start_by_min\n",
    "\n",
    "    for h in range(H):\n",
    "        for w in range(W):\n",
    "            if is_min == True:\n",
    "                decoded_channel[h,w] = min_channel[h,w] + encoded_channel[h,w]\n",
    "            if is_min == False:\n",
    "                decoded_channel[h,w] = max_channel[h,w] - encoded_channel[h,w]\n",
    "\n",
    "            dis_to_min = decoded_channel[h,w] - min_channel[h,w]\n",
    "            dis_to_max = max_channel[h,w] - decoded_channel[h,w]\n",
    "            is_min = (dis_to_min <= dis_to_max)\n",
    "\n",
    "    return decoded_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we test our implementation for a single channel of an image and check that it works well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = channel_encoder_note(x_train[0,:,:,0], 255*np.ones((32,32,)), np.zeros((32,32)))\n",
    "de = channel_decoder_note(en, 255*np.ones((32,32,)), np.zeros((32,32)))\n",
    "np.sum(de != x_train[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoded channel is exactly the same as the original channel. So we are good to go further. Here we will encode the whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD_Encoder_note(X, start_by_min = True):\n",
    "    '''\n",
    "    Min-max differential encoder\n",
    "    Input: - X : numpy array of shape (N, H, W, C) where N is number of images,\n",
    "                 H is heigh, W is width and C is number of channels. We suppose \n",
    "                 that the images in X are very similar\n",
    "           - start_by_min: boolean indicate that we start by difference to min image\n",
    "    Return: Y, (I_min, I_max) where:\n",
    "            - Y : numpy array of the same shape as input, contain the differential parts\n",
    "            - I_min : min image of shape (H, W, C)\n",
    "            - I_max : max_image of shape (H, W, C)   \n",
    "    '''\n",
    "    N, C = X.shape[0], X.shape[3]\n",
    "    Y = np.zeros(X.shape)\n",
    "    I_min = np.min(X, axis=0)\n",
    "    I_max = np.max(X, axis=0)\n",
    "\n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            Y[n,:,:,c] = channel_encoder_note(X[n,:,:,c], I_min[:,:,c], I_max[:,:,c],start_by_min)\n",
    "\n",
    "    return Y, (I_min, I_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD_Decoder_note(Y, I_min, I_max, start_by_min = True):\n",
    "    '''\n",
    "    Min-max differential decoder\n",
    "    Input: Y, (I_min, I_max) where:\n",
    "            - Y : numpy array of the same shape as input, contain the differential parts\n",
    "            - I_min : min image of shape (H, W, C)\n",
    "            - I_max : max_image of shape (H, W, C) \n",
    "            - start_by_min: boolean indicate that we start by difference to min image\n",
    "    Return: - X : numpy array of shape (N, H, W, C) where N is number of images,\n",
    "                 H is heigh, W is width and C is number of channels. \n",
    "    '''\n",
    "    N, C = Y.shape[0], Y.shape[3]\n",
    "    X = np.zeros(Y.shape)\n",
    "\n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            X[n,:,:,c] = channel_decoder_note(Y[n,:,:,c],I_min[:,:,c], I_max[:,:,c],start_by_min)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All elements are ready for the min-max differential method. Below we apply this method to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded, (I_min, I_max) = MMD_Encoder_note(x_train[a[1]])\n",
    "X_decoded = MMD_Decoder_note(X_encoded, I_min, I_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the data and compare the compressed sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./saved_data/X_train_encoded.npy\", X_encoded)\n",
    "np.save(\"./saved_data/X_train.npy\", x_train[a[1]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(X_decoded != X_train[:,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[a[1]].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got the right answer!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ccd7312afbc7f6b085d2146f709040387adf44f7120b2b3d2b8d45900fc5481"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
